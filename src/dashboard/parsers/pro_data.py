"""
–ú–æ–¥—É–ª—å –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ PRO-—Å–µ–∫—Ü–∏–π –∏–∑ —á–µ—Ä–Ω–æ–≤–∏–∫–æ–≤ –æ—Ç—á–µ—Ç–æ–≤ HPI.
"""

import json
import logging
import re
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, TypedDict

from ..normalizers import MetricNormalizer, SphereNormalizer


class SectionContent(TypedDict):
    """–¢–∏–ø –¥–ª—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å–µ–∫—Ü–∏–∏."""

    title: str
    content: str


class TableRow(TypedDict):
    """–¢–∏–ø –¥–ª—è —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã."""

    cells: List[str]
    is_header: bool


@dataclass
class ProMetric:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ PRO-–º–µ—Ç—Ä–∏–∫–µ."""

    sphere: str
    name: str
    description: str
    normalized_name: str
    current_value: Optional[float]
    target_value: Optional[float]
    previous_value: Optional[float] = None
    unit: Optional[str] = ""


@dataclass
class ProData:
    """–î–∞–Ω–Ω—ã–µ –∏–∑ –≤—Å–µ—Ö PRO-—Å–µ–∫—Ü–∏–π."""

    scores: Dict[str, float]  # {—Å—Ñ–µ—Ä–∞: –æ—Ü–µ–Ω–∫–∞}
    metrics: List[ProMetric]  # –°–ø–∏—Å–æ–∫ –º–µ—Ç—Ä–∏–∫
    problems: Dict[str, List[str]]  # {—Å—Ñ–µ—Ä–∞: [–ø—Ä–æ–±–ª–µ–º–∞1, –ø—Ä–æ–±–ª–µ–º–∞2, ...]}
    goals: Dict[str, List[str]]  # {—Å—Ñ–µ—Ä–∞: [—Ü–µ–ª—å1, —Ü–µ–ª—å2, ...]}
    blockers: Dict[str, List[str]]  # {—Å—Ñ–µ—Ä–∞: [–±–ª–æ–∫–µ—Ä1, –±–ª–æ–∫–µ—Ä2, ...]}
    achievements: Dict[str, List[str]]  # {—Å—Ñ–µ—Ä–∞: [–¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ1, –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ2, ...]}
    general_notes: Dict[str, str]  # –ù–æ–≤–æ–µ –ø–æ–ª–µ –¥–ª—è –æ–±—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤


class MetricData(TypedDict):
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ JSON."""

    name: str
    current_value: float
    target_value: float


class MetricsJson(TypedDict):
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è JSON —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏."""

    metrics: Dict[str, List[MetricData]]


class ProDataParser:
    """–ü–∞—Ä—Å–µ—Ä PRO-—Å–µ–∫—Ü–∏–π –∏–∑ —á–µ—Ä–Ω–æ–≤–∏–∫–æ–≤ –æ—Ç—á–µ—Ç–æ–≤."""

    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞."""
        self.sphere_normalizer = SphereNormalizer()
        self.metric_normalizer = MetricNormalizer()
        self.logger = logging.getLogger(__name__)

        # –ù–∞–∑–≤–∞–Ω–∏—è –≤—Å–µ—Ö PRO-—Å–µ–∫—Ü–∏–π
        self.pro_sections: List[str] = [
            "üõë –ú–æ–∏ –ø—Ä–æ–±–ª–µ–º—ã",
            "üéØ –ú–æ–∏ —Ü–µ–ª–∏",
            "üöß –ú–æ–∏ –±–ª–æ–∫–µ—Ä—ã",
            "üèÜ –ú–æ–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è",
            "üìä –ú–æ–∏ –º–µ—Ç—Ä–∏–∫–∏",
            "üìù –û–±—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã",  # –ù–æ–≤–∞—è —Å–µ–∫—Ü–∏—è
        ]

    def _find_section_content(self, content: str, section_title: str) -> Optional[str]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å–µ–∫—Ü–∏–∏ –≤ —Ç–µ–∫—Å—Ç–µ.

        Args:
            content: –í–µ—Å—å —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞
            section_title: –ù–∞–∑–≤–∞–Ω–∏–µ –∏—Å–∫–æ–º–æ–π —Å–µ–∫—Ü–∏–∏

        Returns:
            –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–µ–∫—Ü–∏–∏ –∏–ª–∏ None, –µ—Å–ª–∏ —Å–µ–∫—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
        """
        # –ò—â–µ–º —Å–µ–∫—Ü–∏—é —Å –¥–≤—É–º—è –∏–ª–∏ —Ç—Ä–µ–º—è —Ä–µ—à–µ—Ç–∫–∞–º–∏
        pattern: str = (
            rf"(?:##|###)\s*{re.escape(section_title)}" r"(.*?)(?=(?:##|###)|$)"
        )
        match = re.search(pattern, content, re.DOTALL)
        return match.group(1).strip() if match else None

    def _parse_table_rows(self, table_content: str) -> List[List[str]]:
        """
        –ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã –≤ —Å–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤ –∑–Ω–∞—á–µ–Ω–∏–π.

        Args:
            table_content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ç–∞–±–ª–∏—Ü—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤ –∑–Ω–∞—á–µ–Ω–∏–π –∏–∑ —Ç–∞–±–ª–∏—Ü—ã
        """
        rows: List[List[str]] = []
        if not table_content:
            return rows

        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ
        lines: List[str] = [
            line.strip() for line in table_content.splitlines() if line.strip()
        ]

        for line in lines:
            if line.startswith("|"):
                # –†–∞–∑–±–∏–≤–∞–µ–º —Å—Ç—Ä–æ–∫—É –ø–æ | –∏ —É–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                cells: List[str] = [
                    cell.strip() for cell in line.split("|") if cell.strip()
                ]
                if cells and not any(
                    "---" in cell for cell in cells
                ):  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫—É —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                    rows.append(cells)

        return rows

    def _parse_metrics_section(self, content: str) -> List[ProMetric]:
        """
        –ü–∞—Ä—Å–∏—Ç —Å–µ–∫—Ü–∏—é –º–µ—Ç—Ä–∏–∫.

        Args:
            content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–µ–∫—Ü–∏–∏ –º–µ—Ç—Ä–∏–∫

        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ ProMetric
        """
        metrics: List[ProMetric] = []
        rows = self._parse_table_rows(content)
        for row in rows:
            if len(row) >= 4:
                sphere_candidate = row[0]
                metric_name = row[1]
                current_value = row[2]
                target_value = row[3]
                description = row[4] if len(row) > 4 else ""

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ñ–µ—Ä—É –ø–æ —ç–º–æ–¥–∑–∏ –∏–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏—é
                current_sphere: Optional[str] = None
                for emoji, sphere in self.sphere_normalizer.get_all_emojis().items():
                    if emoji in sphere_candidate:
                        current_sphere = sphere
                        break

                if not current_sphere:
                    current_sphere = self.sphere_normalizer.normalize(sphere_candidate)

                # –í—Å–µ–≥–¥–∞ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º!
                if current_sphere:
                    current_sphere = self.sphere_normalizer.normalize(current_sphere)
                    try:
                        current_float: Optional[float] = (
                            float(current_value) if current_value else None
                        )
                        target_float: Optional[float] = (
                            float(target_value) if target_value else None
                        )
                    except ValueError:
                        self.logger.warning(
                            f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫–∏ "
                            f"'{metric_name}' –≤ —á–∏—Å–ª–∞"
                        )
                        current_float = None
                        target_float = None

                    if current_sphere:
                        metrics.append(
                            ProMetric(
                                sphere=current_sphere,
                                name=metric_name,
                                description=description,
                                normalized_name=self.metric_normalizer.normalize(
                                    metric_name
                                ),
                                current_value=current_float,
                                target_value=target_float,
                            )
                        )
        return metrics

    def _parse_regular_section(self, content: str) -> Dict[str, List[str]]:
        """
        –ü–∞—Ä—Å–∏—Ç –æ–±—ã—á–Ω—É—é —Å–µ–∫—Ü–∏—é (–ø—Ä–æ–±–ª–µ–º—ã, —Ü–µ–ª–∏, –±–ª–æ–∫–µ—Ä—ã, –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è).

        Args:
            content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–µ–∫—Ü–∏–∏

        Returns:
            –°–ª–æ–≤–∞—Ä—å {—Å—Ñ–µ—Ä–∞: [–∑–Ω–∞—á–µ–Ω–∏–µ1, –∑–Ω–∞—á–µ–Ω–∏–µ2, ...]}
        """
        section_data: Dict[str, List[str]] = {}
        rows = self._parse_table_rows(content)
        for row in rows:
            if len(row) >= 2:
                sphere_candidate = row[0]
                value = row[1]

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ñ–µ—Ä—É
                current_sphere: Optional[str] = None
                for emoji, sphere in self.sphere_normalizer.get_all_emojis().items():
                    if emoji in sphere_candidate:
                        current_sphere = sphere
                        break

                if not current_sphere:
                    current_sphere = self.sphere_normalizer.normalize(sphere_candidate)

                # –í—Å–µ–≥–¥–∞ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º!
                if current_sphere:
                    normalized_sphere = self.sphere_normalizer.normalize(current_sphere)
                    # –•—Ä–∞–Ω–∏–º —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ñ–µ—Ä—ã
                    section_data[normalized_sphere] = [value]

        return section_data

    def _parse_general_notes_section(self, content: str) -> Dict[str, str]:
        """
        –ü–∞—Ä—Å–∏—Ç —Å–µ–∫—Ü–∏—é –æ–±—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤/–∑–∞–º–µ—Ç–æ–∫.

        Args:
            content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–µ–∫—Ü–∏–∏

        Returns:
            –°–ª–æ–≤–∞—Ä—å {–≤–æ–ø—Ä–æ—Å: –æ—Ç–≤–µ—Ç}
        """
        notes: Dict[str, str] = {}
        rows = self._parse_table_rows(content)
        for row in rows:
            if len(row) >= 2:
                question = row[0]
                answer = row[1]
                notes[question] = answer
        return notes

    def _parse_metrics_json(self, content: str) -> List[ProMetric]:
        """
        –ü–∞—Ä—Å–∏—Ç –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ JSON-–±–ª–æ–∫–∞.

        Args:
            content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ ProMetric
        """
        metrics: List[ProMetric] = []
        json_block_match = re.search(
            r"## üìä –ú–µ—Ç—Ä–∏–∫–∏ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ\n```json\n(.*?)\n```", content, re.DOTALL
        )
        if json_block_match:
            try:
                metrics_data: MetricsJson = json.loads(json_block_match.group(1))
                for sphere, sphere_metrics in metrics_data.get("metrics", {}).items():
                    for metric_data in sphere_metrics:
                        metrics.append(
                            ProMetric(
                                sphere=sphere,
                                name=metric_data["name"],
                                description="",  # –û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ JSON
                                normalized_name=self.metric_normalizer.normalize(
                                    metric_data["name"]
                                ),
                                current_value=metric_data["current_value"],
                                target_value=metric_data["target_value"],
                            )
                        )
            except Exception as e:
                self.logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ JSON-–±–ª–æ–∫–∞ –º–µ—Ç—Ä–∏–∫: {e}")
        return metrics

    def parse(self, content: str, scores: Optional[Dict[str, float]] = None) -> ProData:
        """
        –ü–∞—Ä—Å–∏—Ç –≤—Å–µ PRO-—Å–µ–∫—Ü–∏–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞.

        Args:
            content: –¢–µ–∫—Å—Ç —á–µ—Ä–Ω–æ–≤–∏–∫–∞
            scores: –°–ª–æ–≤–∞—Ä—å —Å –æ—Ü–µ–Ω–∫–∞–º–∏ —Å—Ñ–µ—Ä (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            –û–±—ä–µ–∫—Ç ProData —Å –¥–∞–Ω–Ω—ã–º–∏ –≤—Å–µ—Ö —Å–µ–∫—Ü–∏–π
        """
        sections_data: Dict[str, Any] = {
            "problems": {},
            "goals": {},
            "blockers": {},
            "achievements": {},
            "metrics": [],
            "general_notes": {},
            "scores": scores or {},
        }

        # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—É—é —Å–µ–∫—Ü–∏—é
        for section_title in self.pro_sections:
            section_content = self._find_section_content(content, section_title)
            if section_content:
                if "–ú–µ—Ç—Ä–∏–∫–∏" in section_title:
                    sections_data["metrics"] = self._parse_metrics_section(
                        section_content
                    )
                elif "–ü—Ä–æ–±–ª–µ–º—ã" in section_title:
                    sections_data["problems"] = self._parse_regular_section(
                        section_content
                    )
                elif "–¶–µ–ª–∏" in section_title:
                    sections_data["goals"] = self._parse_regular_section(
                        section_content
                    )
                elif "–ë–ª–æ–∫–µ—Ä—ã" in section_title:
                    sections_data["blockers"] = self._parse_regular_section(
                        section_content
                    )
                elif "–î–æ—Å—Ç–∏–∂–µ–Ω–∏—è" in section_title:
                    sections_data["achievements"] = self._parse_regular_section(
                        section_content
                    )
                elif "–û–±—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã" in section_title:
                    sections_data["general_notes"] = self._parse_general_notes_section(
                        section_content
                    )

        # –ü—Ä–∏–≤–æ–¥–∏–º —Ç–∏–ø—ã –∫ –æ–∂–∏–¥–∞–µ–º—ã–º –¥–ª—è ProData
        return ProData(
            scores=sections_data.get("scores", {}),
            metrics=sections_data.get("metrics", []),
            problems=sections_data.get("problems", {}),
            goals=sections_data.get("goals", {}),
            blockers=sections_data.get("blockers", {}),
            achievements=sections_data.get("achievements", {}),
            general_notes=sections_data.get("general_notes", {}),
        )
