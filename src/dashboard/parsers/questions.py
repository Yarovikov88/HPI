"""
–ú–æ–¥—É–ª—å –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –±–∞–∑—ã –≤–æ–ø—Ä–æ—Å–æ–≤ HPI.
"""

import json
import logging
import os
import re
from dataclasses import dataclass
from typing import Dict, List, Optional

from ..normalizers import SphereNormalizer


@dataclass
class MetricDefinition:
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –±–∞–∑—ã –≤–æ–ø—Ä–æ—Å–æ–≤."""

    name: str
    unit: Optional[str] = None
    type: Optional[str] = None
    question_text: Optional[str] = None
    is_key_metric: Optional[bool] = False
    value_type: Optional[str] = None


@dataclass
class SphereMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ñ–µ—Ä—ã."""

    sphere_name: str
    sphere_emoji: str
    metrics: List[MetricDefinition]


class QuestionsDatabaseParser:
    """–ü–∞—Ä—Å–µ—Ä –±–∞–∑—ã –≤–æ–ø—Ä–æ—Å–æ–≤ HPI."""

    def __init__(self, database_path: str):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞.

        Args:
            database_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –±–∞–∑—ã –≤–æ–ø—Ä–æ—Å–æ–≤ (questions.md)
        """
        self.database_path = database_path
        self.sphere_normalizer = SphereNormalizer()
        self.logger = logging.getLogger(__name__)

    def _extract_json_blocks(self, content: str) -> Dict[str, str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç JSON-–±–ª–æ–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ñ–µ—Ä—ã –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞.

        Args:
            content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –±–∞–∑—ã –≤–æ–ø—Ä–æ—Å–æ–≤

        Returns:
            –°–ª–æ–≤–∞—Ä—å {–Ω–∞–∑–≤–∞–Ω–∏–µ_—Å—Ñ–µ—Ä—ã: json_–±–ª–æ–∫}
        """
        json_blocks = {}

        # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∏–ø–∞ "## üíñ –û—Ç–Ω–æ—à–µ–Ω–∏—è —Å –ª—é–±–∏–º—ã–º–∏" –∏ —Å–ª–µ–¥—É—é—â–∏–π –∑–∞ –Ω–∏–º –±–ª–æ–∫ ```json ... ```
        pattern = re.compile(
            r"##\\s*(?P<emoji>[\\U0001F000-\\U0001FA95\\s\\S]+?)\\s*(?P<name>.*?)"
            r"\\n```json\\n([\\s\\S]+?)\\n```",
            re.DOTALL,
        )

        for match in pattern.finditer(content):
            emoji = match.group("emoji").strip()
            json_content = match.group(3)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –≤–∞–ª–∏–¥–Ω–∞—è —Å—Ñ–µ—Ä–∞
            sphere = self.sphere_normalizer.get_sphere_by_emoji(emoji)
            if sphere:
                json_blocks[sphere] = json_content
            else:
                self.logger.warning(f"–ù–∞–π–¥–µ–Ω –±–ª–æ–∫ —Å –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–º —ç–º–æ–¥–∑–∏: {emoji}")

        return json_blocks

    def _parse_metrics_from_json(self, json_content: str) -> List[MetricDefinition]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –∏–∑ JSON-–±–ª–æ–∫–∞.

        Args:
            json_content: JSON-—Å—Ç—Ä–æ–∫–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ —Å—Ñ–µ—Ä—ã

        Returns:
            –°–ø–∏—Å–æ–∫ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –º–µ—Ç—Ä–∏–∫
        """
        metrics = []
        try:
            data = json.loads(json_content)
            for item in data:
                if item.get("category") == "metrics" and "metrics" in item:
                    for metric in item["metrics"]:
                        metrics.append(
                            MetricDefinition(
                                name=metric.get("name", ""),
                                unit=metric.get("unit"),
                                type=metric.get("type"),
                            )
                        )
        except json.JSONDecodeError as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON: {e}")

        return metrics

    def parse(self) -> List[SphereMetrics]:
        """
        –ü–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª –±–∞–∑—ã –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ —Å—Ñ–µ—Ä–∞–º.

        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ SphereMetrics —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ñ–µ—Ä—ã
        """
        if not os.path.exists(self.database_path):
            self.logger.error(
                f"–§–∞–π–ª –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.database_path}"
            )
            return []

        try:
            with open(self.database_path, "r", encoding="utf-8") as f:
                content = f.read()
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –±–∞–∑—ã –≤–æ–ø—Ä–æ—Å–æ–≤: {e}")
            return []

        # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON-–±–ª–æ–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ñ–µ—Ä—ã
        json_blocks = self._extract_json_blocks(content)

        # –ü–∞—Ä—Å–∏–º –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –∫–∞–∂–¥–æ–≥–æ –±–ª–æ–∫–∞
        sphere_metrics = []
        for sphere_name, json_content in json_blocks.items():
            metrics = self._parse_metrics_from_json(json_content)
            if metrics:
                sphere_emoji = self.sphere_normalizer.get_emoji_by_sphere(sphere_name)
                if sphere_emoji:
                    sphere_metrics.append(
                        SphereMetrics(
                            sphere_name=sphere_name,
                            sphere_emoji=sphere_emoji,
                            metrics=metrics,
                        )
                    )

        self.logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω—ã –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è {len(sphere_metrics)} —Å—Ñ–µ—Ä")
        return sphere_metrics

    def get_metric_names(self, sphere: Optional[str] = None) -> List[str]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫.

        Args:
            sphere: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ñ–µ—Ä—ã –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏

        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –º–µ—Ç—Ä–∏–∫
        """
        metrics = []
        for sphere_metrics in self.parse():
            if not sphere or sphere_metrics.sphere_name == sphere:
                metrics.extend([m.name for m in sphere_metrics.metrics])
        return metrics

    def parse_spheres_master_list(self) -> List[str]:
        """
        –ü–∞—Ä—Å–∏—Ç master-—Ç–∞–±–ª–∏—Ü—É —Å—Ñ–µ—Ä –∏–∑ –Ω–∞—á–∞–ª–∞ —Ñ–∞–π–ª–∞ questions.md –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π —Å—Ñ–µ—Ä.
        """
        if not os.path.exists(self.database_path):
            self.logger.error(
                f"–§–∞–π–ª –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.database_path}"
            )
            return []
        try:
            with open(self.database_path, "r", encoding="utf-8") as f:
                content = f.read()
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –±–∞–∑—ã –≤–æ–ø—Ä–æ—Å–æ–≤: {e}")
            return []
        # –ò—â–µ–º —Ç–∞–±–ª–∏—Ü—É —Å—Ñ–µ—Ä
        pattern = re.compile(
            r"\\|\\s*–ö–æ—Ä–æ—Ç–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ\\s*\\|.*?\\n(\\|.*?\\n)+", re.DOTALL
        )
        match = pattern.search(content)
        if not match:
            self.logger.error("–ù–µ –Ω–∞–π–¥–µ–Ω–∞ master-—Ç–∞–±–ª–∏—Ü–∞ —Å—Ñ–µ—Ä –≤ –±–∞–∑–µ –≤–æ–ø—Ä–æ—Å–æ–≤!")
            return []
        table = match.group(0)
        lines = [
            line  # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º l –≤ –±–æ–ª–µ–µ –ø–æ–Ω—è—Ç–Ω–æ–µ –∏–º—è line
            for line in table.splitlines()
            if line.strip().startswith("|") and not line.strip().startswith("|:")
        ]
        spheres = []
        for line in lines[1:]:  # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º l –≤ –±–æ–ª–µ–µ –ø–æ–Ω—è—Ç–Ω–æ–µ –∏–º—è line
            parts = [p.strip() for p in line.strip("|").split("|")]
            if len(parts) >= 3:
                spheres.append(parts[1])  # –ü–æ–ª–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        return spheres

    def _parse_metric_data(self, metric_data: dict) -> Optional[SphereMetrics]:
        """–ü–∞—Ä—Å–∏—Ç –¥–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ —Å–ª–æ–≤–∞—Ä—è."""
        try:
            sphere = metric_data.get("sphere")
            if not sphere:
                return None

            sphere_emoji = self.sphere_normalizer.get_emoji_by_sphere(sphere)
            if not sphere_emoji:
                return None

            return SphereMetrics(
                sphere_name=sphere, sphere_emoji=sphere_emoji, metrics=[]
            )
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫–∏: {e}")
            return None

    def _parse_lines(self, lines: List[str]) -> List[str]:
        """–ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫–∏ —Ñ–∞–π–ª–∞."""
        result = []
        for line in lines:  # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º l –≤ –±–æ–ª–µ–µ –ø–æ–Ω—è—Ç–Ω–æ–µ –∏–º—è line
            if line.strip():
                result.append(line.strip())
        return result

    def _parse_sphere_from_question(
        self, question_text: str
    ) -> Optional[SphereMetrics]:
        """–ü–∞—Ä—Å–∏—Ç –¥–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –≤–æ–ø—Ä–æ—Å–∞."""
        try:
            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ —Ç–µ–∫—Å—Ç–µ –≤–æ–ø—Ä–æ—Å–∞
            metrics = []
            pattern = re.compile(
                r"##\\s*(?P<emoji>[\\U0001F000-\\U0001FA95\\s\\S]+?)\\s*(?P<name>.*?)"
                r"\\n```json\\n([\\s\\S]+?)\\n```",
                re.DOTALL,
            )
            for match in pattern.finditer(question_text):
                emoji = match.group("emoji").strip()
                name = match.group("name").strip()

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –≤–∞–ª–∏–¥–Ω–∞—è —Å—Ñ–µ—Ä–∞
                sphere = self.sphere_normalizer.get_sphere_by_emoji(emoji)
                if sphere:
                    metrics.append(MetricDefinition(name=name))
                else:
                    self.logger.warning(f"–ù–∞–π–¥–µ–Ω –±–ª–æ–∫ —Å –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–º —ç–º–æ–¥–∑–∏: {emoji}")

            if metrics:
                sphere_emoji = self.sphere_normalizer.get_emoji_by_sphere(
                    metrics[0].name
                )
                if sphere_emoji:
                    return SphereMetrics(
                        sphere_name=metrics[0].name,
                        sphere_emoji=sphere_emoji,
                        metrics=metrics,
                    )
                else:
                    return None
            else:
                return None
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫–∏: {e}")
            return None

    def parse_questions_from_text(self, text: str) -> List[SphereMetrics]:
        """–ü–∞—Ä—Å–∏—Ç –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –≤–æ–ø—Ä–æ—Å–∞."""
        # –†–∞–∑–¥–µ–ª—è–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
        questions = re.split(r"##\\s*–û—Ç–≤–µ—Ç\\s*", text, flags=re.DOTALL)
        sphere_metrics: Dict[str, Optional[SphereMetrics]] = {}
        questions_map = {q.name.lower(): q for s in self.parse() for q in s.metrics}

        for question in questions:
            if question.strip():
                sphere_metrics[question.split("\\n")[0].strip()] = (
                    self._parse_sphere_from_question(question)
                )

        for _, metrics in sphere_metrics.items():
            if metrics:
                for metric in metrics.metrics:
                    # –ù–∞—Ö–æ–¥–∏–º –≤–æ–ø—Ä–æ—Å –ø–æ –∏–º–µ–Ω–∏ –º–µ—Ç—Ä–∏–∫–∏
                    question_text_lower = metric.name.lower()
                    if question_text_lower in questions_map:
                        question_data = questions_map[question_text_lower]
                        metric.question_text = question_data.question_text
                        metric.is_key_metric = question_data.is_key_metric
                        metric.value_type = question_data.value_type

        return [m for m in sphere_metrics.values() if m is not None]
